{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41d62d3",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification using Machine Learning\n",
    "This notebook implements various machine learning models to classify breast cancer data. The workflow includes:\n",
    "1. Data Loading & Exploration\n",
    "2. Data Preprocessing\n",
    "3. Training SVM & Ensemble Models\n",
    "4. Model Evaluation\n",
    "5. Visualization of Results using SHAP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf7d64d",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ae7aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "import math\n",
    "import dagshub\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dvc\n",
    "import dvc.api\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e52ad7",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration\n",
    "This function loads the dataset, assigns column names, and provides an overview.\n",
    "It also checks for missing values and displays class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4fa1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_data(filepath='../Data/wdbc.data'):\n",
    "    print(\"Loading dataset...\")\n",
    "    columns = [\n",
    "        \"ID\", \"Class\",\n",
    "        \"Radius_Mean\", \"Texture_Mean\", \"Perimeter_Mean\", \"Area_Mean\", \"Smoothness_Mean\", \"Compactness_Mean\",\n",
    "        \"Concavity_Mean\", \"ConcavePoints_Mean\", \"Symmetry_Mean\", \"FractalDimension_Mean\",\n",
    "        \"Radius_SE\", \"Texture_SE\", \"Perimeter_SE\", \"Area_SE\", \"Smoothness_SE\", \"Compactness_SE\",\n",
    "        \"Concavity_SE\", \"ConcavePoints_SE\", \"Symmetry_SE\", \"FractalDimension_SE\",\n",
    "        \"Radius_Worst\", \"Texture_Worst\", \"Perimeter_Worst\", \"Area_Worst\", \"Smoothness_Worst\",\n",
    "        \"Compactness_Worst\", \"Concavity_Worst\", \"ConcavePoints_Worst\", \"Symmetry_Worst\", \"FractalDimension_Worst\"\n",
    "    ]\n",
    "    df = pd.read_csv(filepath,  header=None, names=columns)\n",
    "\n",
    "    df['Class'] = df['Class'].map({'M': 1, 'B': 0})\n",
    "\n",
    "    print(\"\\nDataset Overview:\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"\\nClass distribution:\")\n",
    "    print(df['Class'].value_counts())\n",
    "    print(f\"Fraud percentage: {df['Class'].mean() * 100:.4f}%\")\n",
    "\n",
    "    print(\"\\nChecking for missing values:\")\n",
    "    print(df.isnull().sum().any())\n",
    "\n",
    "\n",
    "    print(\"\\nBasic statistics for anonymized features:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b841d",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "This function prepares the data for model training:\n",
    "- Removes the ID column\n",
    "- Splits data into train-test sets\n",
    "- Standardizes the features\n",
    "- Handles class imbalance using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf680095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    print(\"\\nPreprocessing data...\")\n",
    "\n",
    "    #drop the ID column and label\n",
    "    X = df.drop('Class', axis=1).drop('ID',axis=1)\n",
    "    y = df['Class']\n",
    "\n",
    "    # Split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Handle imbalanced data with SMOTE (only for training data)\n",
    "    print(\"Applying SMOTE to handle class imbalance...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    print(f\"After SMOTE - Training set shape: {X_train_resampled.shape}\")\n",
    "    print(f\"Class distribution after SMOTE: {pd.Series(y_train_resampled).value_counts()}\")\n",
    "\n",
    "    return X_train_resampled, X_test_scaled, y_train_resampled, y_test, scaler, X_train.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838e8ad",
   "metadata": {},
   "source": [
    "## Training SVM Models\n",
    "Trains SVM models with three different kernels: Linear, RBF, and Polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d34ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"AnasAljaour/AIDE505-FinalProject\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"AnasAljaour/AIDE505-FinalProject\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository AnasAljaour/AIDE505-FinalProject initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository AnasAljaour/AIDE505-FinalProject initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initialized dagshub\n",
    "dagshub.init(repo_owner='AnasAljaour', repo_name='AIDE505-FinalProject', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88be1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_models(X_train, y_train, X_test, y_test):\n",
    "    print(\"\\nTraining SVM models with different kernels...\")\n",
    "    svm_models = {\n",
    "        'SVM (Linear)': SVC(kernel='linear', probability=True, random_state=42),\n",
    "        'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "        'SVM (Polynomial)': SVC(kernel='poly', degree=3, probability=True, random_state=42)\n",
    "        }\n",
    "    \n",
    "    os.makedirs(\"ConfusionMatrix\", exist_ok=True)\n",
    "    os.makedirs('ClassificationReports', exist_ok=True)    \n",
    "    dvc_version = dvc.api.get_url(\"../Data/wdbc.data\", rev=\"HEAD\")  # or use a specific revision\n",
    "        \n",
    "    for name, model in svm_models.items():\n",
    "        with mlflow.start_run(run_name = name):\n",
    "            print(f\"Training {name}...\")\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred =  model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            kernel_type = model.get_params()[\"kernel\"]\n",
    "            mlflow.log_param(\"dataset_version\", dvc_version)\n",
    "            mlflow.log_param(\"kernel\", kernel_type)\n",
    "            mlflow.log_param(\"accuracy\", accuracy)\n",
    "            mlflow.sklearn.log_model(model, artifact_path=name)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            cm_df = pd.DataFrame(cm, index=[\"Actual Negative (N)\", \"Actual Positive (P)\"],\n",
    "                                   columns=[\"Predicted Negative (N)\", \"Predicted Positive (P)\"])\n",
    "            cm_df.to_csv(f\"./ConfusionMatrix/confusion_matrix_{name}.csv\", index=True)\n",
    "            mlflow.log_artifact(f\"./ConfusionMatrix/confusion_matrix_{name}.csv\")\n",
    "\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            report_df = pd.DataFrame(report).transpose()  # Convert to DataFrame for better readability\n",
    "            report_path = f\"ClassificationReports/classification_report_{name}.csv\"\n",
    "            report_df.to_csv(report_path, index=True)\n",
    "            mlflow.log_artifact(report_path)\n",
    "\n",
    "    return svm_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3786b2be",
   "metadata": {},
   "source": [
    "## Training Ensemble Models\n",
    "Implements Bagging, Random Forest, and Boosting using Decision Trees.\n",
    "Also combines SVMs in a Voting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b617cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble_models(X_train, y_train,X_test, y_test, svm_models):\n",
    "    print(\"\\nTraining ensemble models...\")\n",
    "\n",
    "    num_models = 20\n",
    "    sample_size = 0.5\n",
    "    feature_sample_size = 0.8\n",
    "    dvc_version = dvc.api.get_url(\"../Data/wdbc.data\", rev=\"HEAD\")  # or use a specific revision\n",
    "    np.random.seed(0)\n",
    "\n",
    "    \n",
    "\n",
    "    # for normal bagging using decision tree\n",
    "    with mlflow.start_run(run_name = 'Bagging using Decision tree'):\n",
    "        bagging_clf = BaggingClassifier(\n",
    "            estimator=DecisionTreeClassifier(),\n",
    "            n_estimators=num_models,\n",
    "            max_features=feature_sample_size,\n",
    "            max_samples=sample_size,\n",
    "            random_state=42\n",
    "        )\n",
    "        bagging_clf.fit(X_train, y_train)\n",
    "        y_pred =  bagging_clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        cm_df = pd.DataFrame(cm, index=[\"Actual Negative (N)\", \"Actual Positive (P)\"],\n",
    "                                   columns=[\"Predicted Negative (N)\", \"Predicted Positive (P)\"])\n",
    "        cm_df.to_csv(f\"./ConfusionMatrix/confusion_matrix_Bagging.csv\", index=True)\n",
    "        mlflow.log_artifact(\"./ConfusionMatrix/confusion_matrix_Bagging.csv\")\n",
    "        mlflow.log_param(\"n_estimators\", num_models)\n",
    "        mlflow.log_param(\"max_features\", feature_sample_size)\n",
    "        mlflow.log_param(\"max_samples\", sample_size)\n",
    "        mlflow.log_param(\"accuracy\", accuracy)\n",
    "        mlflow.log_param('dataset_version', dvc_version)\n",
    "        mlflow.sklearn.log_model(bagging_clf, \"BaggingClassifierModel\")\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()  # Convert to DataFrame for better readability\n",
    "        report_path = f\"ClassificationReports/classification_report_bagging.csv\"\n",
    "        report_df.to_csv(report_path, index=True)\n",
    "        mlflow.log_artifact(report_path)\n",
    "        \n",
    "\n",
    "    with mlflow.start_run(run_name = 'RandomForestClassifier'):\n",
    "        rf_clf = RandomForestClassifier(\n",
    "            n_estimators=num_models,\n",
    "            max_features=feature_sample_size,\n",
    "            max_samples=sample_size,\n",
    "            random_state=42\n",
    "        )\n",
    "         \n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        y_pred = rf_clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_param(\"n_estimators\", num_models)\n",
    "        mlflow.log_param(\"max_features\", feature_sample_size)\n",
    "        mlflow.log_param(\"max_samples\", sample_size)\n",
    "        mlflow.log_param(\"accuracy\", accuracy)\n",
    "        mlflow.log_param('dataset_version', dvc_version)\n",
    "        mlflow.sklearn.log_model(rf_clf, \"RandomForestClassifier\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        cm_df = pd.DataFrame(cm, index=[\"Actual Negative (N)\", \"Actual Positive (P)\"],\n",
    "                                   columns=[\"Predicted Negative (N)\", \"Predicted Positive (P)\"])\n",
    "        cm_df.to_csv(f\"./ConfusionMatrix/confusion_matrix_RandomForestClassifier.csv\", index=True)\n",
    "        mlflow.log_artifact(\"./ConfusionMatrix/confusion_matrix_RandomForestClassifier.csv\")\n",
    "\n",
    "\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()  \n",
    "        report_path = f\"ClassificationReports/classification_report_rm.csv\"\n",
    "        report_df.to_csv(report_path, index=True)\n",
    "        mlflow.log_artifact(report_path)\n",
    "\n",
    "    with mlflow.start_run(run_name='Boosting using Decision tree'):\n",
    "        boosting_clf = AdaBoostClassifier(\n",
    "            estimator=DecisionTreeClassifier(),\n",
    "            n_estimators=num_models,\n",
    "            random_state=42\n",
    "            )\n",
    "        boosting_clf.fit(X_train, y_train)\n",
    "        y_pred = boosting_clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        \n",
    "        mlflow.log_param(\"n_estimators\", num_models)\n",
    "        mlflow.log_param(\"accuracy\", accuracy)\n",
    "        mlflow.log_param('dataset_version', dvc_version)\n",
    "        mlflow.sklearn.log_model(boosting_clf, \"BoostingClassifierModel\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        cm_df = pd.DataFrame(cm, index=[\"Actual Negative (N)\", \"Actual Positive (P)\"],\n",
    "                                   columns=[\"Predicted Negative (N)\", \"Predicted Positive (P)\"])\n",
    "        cm_df.to_csv(f\"./ConfusionMatrix/confusion_matrix_Boosting.csv\", index=True)\n",
    "        mlflow.log_artifact(\"./ConfusionMatrix/confusion_matrix_Boosting.csv\")\n",
    "\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()  \n",
    "        report_path = f\"ClassificationReports/classification_report_boosting.csv\"\n",
    "        report_df.to_csv(report_path, index=True)\n",
    "        mlflow.log_artifact(report_path)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    all_models = {\n",
    "        'SVM (Linear)': svm_models['SVM (Linear)'],\n",
    "        'SVM (RBF)': svm_models['SVM (RBF)'],\n",
    "        'SVM (Polynomial)': svm_models['SVM (Polynomial)'],\n",
    "        'Bagging': bagging_clf,\n",
    "        'Boosting': boosting_clf,\n",
    "        'Random Forest': rf_clf,\n",
    "    }\n",
    "    \n",
    "\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c470a100",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluates models using classification reports and confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75230fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X_test, y_test):\n",
    "    print(\"\\nEvaluating models...\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nEvaluating {name}:\")\n",
    "\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        \n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(cm)\n",
    "        results[name] = {\n",
    "            'y_pred': y_pred,\n",
    "            'y_prob': y_prob,\n",
    "            'confusion_matrix': cm,\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58898449",
   "metadata": {},
   "source": [
    "## Running the Workflow\n",
    "Now we execute all the steps in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7a308b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "\n",
      "Dataset Overview:\n",
      "Shape: (569, 32)\n",
      "\n",
      "Class distribution:\n",
      "Class\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64\n",
      "Fraud percentage: 37.2583%\n",
      "\n",
      "Checking for missing values:\n",
      "False\n",
      "\n",
      "Basic statistics for anonymized features:\n",
      "                 ID       Class  Radius_Mean  Texture_Mean  Perimeter_Mean  \\\n",
      "count  5.690000e+02  569.000000   569.000000    569.000000      569.000000   \n",
      "mean   3.037183e+07    0.372583    14.127292     19.289649       91.969033   \n",
      "std    1.250206e+08    0.483918     3.524049      4.301036       24.298981   \n",
      "min    8.670000e+03    0.000000     6.981000      9.710000       43.790000   \n",
      "25%    8.692180e+05    0.000000    11.700000     16.170000       75.170000   \n",
      "50%    9.060240e+05    0.000000    13.370000     18.840000       86.240000   \n",
      "75%    8.813129e+06    1.000000    15.780000     21.800000      104.100000   \n",
      "max    9.113205e+08    1.000000    28.110000     39.280000      188.500000   \n",
      "\n",
      "         Area_Mean  Smoothness_Mean  Compactness_Mean  Concavity_Mean  \\\n",
      "count   569.000000       569.000000        569.000000      569.000000   \n",
      "mean    654.889104         0.096360          0.104341        0.088799   \n",
      "std     351.914129         0.014064          0.052813        0.079720   \n",
      "min     143.500000         0.052630          0.019380        0.000000   \n",
      "25%     420.300000         0.086370          0.064920        0.029560   \n",
      "50%     551.100000         0.095870          0.092630        0.061540   \n",
      "75%     782.700000         0.105300          0.130400        0.130700   \n",
      "max    2501.000000         0.163400          0.345400        0.426800   \n",
      "\n",
      "       ConcavePoints_Mean  ...  Radius_Worst  Texture_Worst  Perimeter_Worst  \\\n",
      "count          569.000000  ...    569.000000     569.000000       569.000000   \n",
      "mean             0.048919  ...     16.269190      25.677223       107.261213   \n",
      "std              0.038803  ...      4.833242       6.146258        33.602542   \n",
      "min              0.000000  ...      7.930000      12.020000        50.410000   \n",
      "25%              0.020310  ...     13.010000      21.080000        84.110000   \n",
      "50%              0.033500  ...     14.970000      25.410000        97.660000   \n",
      "75%              0.074000  ...     18.790000      29.720000       125.400000   \n",
      "max              0.201200  ...     36.040000      49.540000       251.200000   \n",
      "\n",
      "        Area_Worst  Smoothness_Worst  Compactness_Worst  Concavity_Worst  \\\n",
      "count   569.000000        569.000000         569.000000       569.000000   \n",
      "mean    880.583128          0.132369           0.254265         0.272188   \n",
      "std     569.356993          0.022832           0.157336         0.208624   \n",
      "min     185.200000          0.071170           0.027290         0.000000   \n",
      "25%     515.300000          0.116600           0.147200         0.114500   \n",
      "50%     686.500000          0.131300           0.211900         0.226700   \n",
      "75%    1084.000000          0.146000           0.339100         0.382900   \n",
      "max    4254.000000          0.222600           1.058000         1.252000   \n",
      "\n",
      "       ConcavePoints_Worst  Symmetry_Worst  FractalDimension_Worst  \n",
      "count           569.000000      569.000000              569.000000  \n",
      "mean              0.114606        0.290076                0.083946  \n",
      "std               0.065732        0.061867                0.018061  \n",
      "min               0.000000        0.156500                0.055040  \n",
      "25%               0.064930        0.250400                0.071460  \n",
      "50%               0.099930        0.282200                0.080040  \n",
      "75%               0.161400        0.317900                0.092080  \n",
      "max               0.291000        0.663800                0.207500  \n",
      "\n",
      "[8 rows x 32 columns]\n",
      "\n",
      "Preprocessing data...\n",
      "Training set shape: (455, 30)\n",
      "Testing set shape: (114, 30)\n",
      "Applying SMOTE to handle class imbalance...\n",
      "After SMOTE - Training set shape: (570, 30)\n",
      "Class distribution after SMOTE: Class\n",
      "1    285\n",
      "0    285\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training SVM models with different kernels...\n",
      "Training SVM (Linear)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/02 13:15:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run SVM (Linear) at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0/runs/e695ea0aa4344469907ac6085ce382f7\n",
      "üß™ View experiment at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0\n",
      "Training SVM (RBF)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/02 13:15:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run SVM (RBF) at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0/runs/c70cda5c4ebf45ba9527e32e79d04e68\n",
      "üß™ View experiment at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0\n",
      "Training SVM (Polynomial)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/02 13:15:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run SVM (Polynomial) at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0/runs/1d7c7bd1831642c695a66f9189b75f26\n",
      "üß™ View experiment at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0\n",
      "\n",
      "Training ensemble models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/02 13:16:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Bagging using Decision tree at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0/runs/908224f66d8c47a7a8c5826c0e2b0b51\n",
      "üß™ View experiment at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/02 13:16:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run RandomForestClassifier at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0/runs/76119866719d4b18a5666dbeb7e57e00\n",
      "üß™ View experiment at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "2025/04/02 13:16:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Boosting using Decision tree at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0/runs/b8e7639c4925422b879dcd38813082dc\n",
      "üß™ View experiment at: https://dagshub.com/AnasAljaour/AIDE505-FinalProject.mlflow/#/experiments/0\n",
      "\n",
      "Evaluating models...\n",
      "\n",
      "Evaluating SVM (Linear):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        72\n",
      "           1       0.98      0.95      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "[[71  1]\n",
      " [ 2 40]]\n",
      "\n",
      "Evaluating SVM (RBF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        72\n",
      "           1       0.98      0.95      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "[[71  1]\n",
      " [ 2 40]]\n",
      "\n",
      "Evaluating SVM (Polynomial):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        72\n",
      "           1       1.00      0.81      0.89        42\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.95      0.90      0.92       114\n",
      "weighted avg       0.94      0.93      0.93       114\n",
      "\n",
      "[[72  0]\n",
      " [ 8 34]]\n",
      "\n",
      "Evaluating Bagging:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        72\n",
      "           1       0.97      0.93      0.95        42\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "[[71  1]\n",
      " [ 3 39]]\n",
      "\n",
      "Evaluating Boosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92        72\n",
      "           1       0.89      0.81      0.85        42\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.88      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "[[68  4]\n",
      " [ 8 34]]\n",
      "\n",
      "Evaluating Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        72\n",
      "           1       1.00      0.93      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.96      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "[[72  0]\n",
      " [ 3 39]]\n",
      "\n",
      "Execution completed! Check the output directory for evaluation metrics and explanations.\n"
     ]
    }
   ],
   "source": [
    "df = load_and_explore_data()\n",
    "X_train, X_test, y_train, y_test, scaler, feature_names = preprocess_data(df)\n",
    "svm_models = train_svm_models(X_train, y_train, X_test, y_test)\n",
    "all_models = train_ensemble_models(X_train, y_train,X_test, y_test, svm_models)\n",
    "evaluation_results = evaluate_models(all_models,  X_test, y_test)\n",
    "print(\"\\nExecution completed! Check the output directory for evaluation metrics and explanations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df1ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
