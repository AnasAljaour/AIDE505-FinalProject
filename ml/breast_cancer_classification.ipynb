{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41d62d3",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification using Machine Learning\n",
    "This notebook implements various machine learning models to classify breast cancer data. The workflow includes:\n",
    "1. Data Loading & Exploration\n",
    "2. Data Preprocessing\n",
    "3. Training SVM & Ensemble Models\n",
    "4. Model Evaluation\n",
    "5. Visualization of Results using SHAP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf7d64d",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "import math\n",
    "import dagshub\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dvc\n",
    "import dvc.api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e52ad7",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration\n",
    "This function loads the dataset, assigns column names, and provides an overview.\n",
    "It also checks for missing values and displays class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4fa1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_data(filepath='../Data/wdbc.data'):\n",
    "    print(\"Loading dataset...\")\n",
    "    columns = [\n",
    "        \"ID\", \"Class\",\n",
    "        \"Radius_Mean\", \"Texture_Mean\", \"Perimeter_Mean\", \"Area_Mean\", \"Smoothness_Mean\", \"Compactness_Mean\",\n",
    "        \"Concavity_Mean\", \"ConcavePoints_Mean\", \"Symmetry_Mean\", \"FractalDimension_Mean\",\n",
    "        \"Radius_SE\", \"Texture_SE\", \"Perimeter_SE\", \"Area_SE\", \"Smoothness_SE\", \"Compactness_SE\",\n",
    "        \"Concavity_SE\", \"ConcavePoints_SE\", \"Symmetry_SE\", \"FractalDimension_SE\",\n",
    "        \"Radius_Worst\", \"Texture_Worst\", \"Perimeter_Worst\", \"Area_Worst\", \"Smoothness_Worst\",\n",
    "        \"Compactness_Worst\", \"Concavity_Worst\", \"ConcavePoints_Worst\", \"Symmetry_Worst\", \"FractalDimension_Worst\"\n",
    "    ]\n",
    "    df = pd.read_csv(filepath,  header=None, names=columns)\n",
    "\n",
    "    df['Class'] = df['Class'].map({'M': 1, 'B': 0})\n",
    "\n",
    "    print(\"\\nDataset Overview:\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"\\nClass distribution:\")\n",
    "    print(df['Class'].value_counts())\n",
    "    print(f\"Fraud percentage: {df['Class'].mean() * 100:.4f}%\")\n",
    "\n",
    "    print(\"\\nChecking for missing values:\")\n",
    "    print(df.isnull().sum().any())\n",
    "\n",
    "\n",
    "    print(\"\\nBasic statistics for anonymized features:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b841d",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "This function prepares the data for model training:\n",
    "- Removes the ID column\n",
    "- Splits data into train-test sets\n",
    "- Standardizes the features\n",
    "- Handles class imbalance using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf680095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    print(\"\\nPreprocessing data...\")\n",
    "\n",
    "    #drop the ID column and label\n",
    "    X = df.drop('Class', axis=1).drop('ID',axis=1)\n",
    "    y = df['Class']\n",
    "\n",
    "    # Split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Handle imbalanced data with SMOTE (only for training data)\n",
    "    print(\"Applying SMOTE to handle class imbalance...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    print(f\"After SMOTE - Training set shape: {X_train_resampled.shape}\")\n",
    "    print(f\"Class distribution after SMOTE: {pd.Series(y_train_resampled).value_counts()}\")\n",
    "\n",
    "    return X_train_resampled, X_test_scaled, y_train_resampled, y_test, scaler, X_train.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838e8ad",
   "metadata": {},
   "source": [
    "## Training SVM Models\n",
    "Trains SVM models with three different kernels: Linear, RBF, and Polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d34ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as AnasAljaour\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as AnasAljaour\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository  AIDE505-FinalProject doesn't exist, creating it under current user.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository  AIDE505-FinalProject doesn't exist, creating it under current user.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Response (422):\n",
      "[{\"fieldNames\":[\"Name\"],\"classification\":\"AlphaDashDotError\",\"message\":\"AlphaDashDot\"}]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Repository name is invalid or it already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRepoNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\dagshub\\common\\init.py:88\u001b[0m, in \u001b[0;36minit\u001b[1;34m(repo_name, repo_owner, url, root, host, mlflow, dvc, patch_mlflow)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[43mrepo_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_repo_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepoNotFoundError:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\dagshub\\common\\api\\repo.py:103\u001b[0m, in \u001b[0;36mRepoAPI.get_repo_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepoNotFoundError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepoNotFoundError\u001b[0m: Repo https://dagshub.com/AnasAljaour/%20AIDE505-FinalProject not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#initialized dagshub\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdagshub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_owner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAnasAljaour\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m AIDE505-FinalProject\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\dagshub\\common\\init.py:91\u001b[0m, in \u001b[0;36minit\u001b[1;34m(repo_name, repo_owner, url, root, host, mlflow, dvc, patch_mlflow)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepoNotFoundError:\n\u001b[0;32m     90\u001b[0m     log_message(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepository \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist, creating it under current user.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m     \u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Get the token for the configs\u001b[39;00m\n\u001b[0;32m     94\u001b[0m token \u001b[38;5;241m=\u001b[39m get_token(host\u001b[38;5;241m=\u001b[39mhost)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\DeepLearning\\lib\\site-packages\\dagshub\\upload\\wrapper.py:165\u001b[0m, in \u001b[0;36mcreate_repo\u001b[1;34m(repo_name, org_name, description, private, auto_init, gitignores, license, readme, template, host)\u001b[0m\n\u001b[0;32m    163\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m HTTPStatus\u001b[38;5;241m.\u001b[39mUNPROCESSABLE_ENTITY:\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepository name is invalid or it already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to create the desired repository.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Repository name is invalid or it already exists."
     ]
    }
   ],
   "source": [
    "#initialized dagshub\n",
    "dagshub.init(repo_owner='AnasAljaour', repo_name='AIDE505-FinalProject', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_models(X_train, y_train, X_test, y_test):\n",
    "    print(\"\\nTraining SVM models with different kernels...\")\n",
    "    svm_models = {\n",
    "        'SVM (Linear)': SVC(kernel='linear', probability=True, random_state=42),\n",
    "        'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "        'SVM (Polynomial)': SVC(kernel='poly', degree=3, probability=True, random_state=42)\n",
    "        }\n",
    "    \n",
    "        \n",
    "    dvc_version = dvc.api.get_url(\"../Data/wdbc.data\", rev=\"HEAD\")  # or use a specific revision\n",
    "        \n",
    "    for name, model in svm_models.items():\n",
    "        with mlflow.start_run(run_name = name):\n",
    "            print(f\"Training {name}...\")\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred =  model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            kernel_type = model.get_params()[\"kernel\"]\n",
    "            mlflow.log_param(\"dataset_version\", dvc_version)\n",
    "            mlflow.log_param(\"kernel\", kernel_type)\n",
    "            mlflow.log_param(\"accuracy\", accuracy)\n",
    "            mlflow.sklearn.log_model(model, artifact_path=name)\n",
    "\n",
    "    return svm_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3786b2be",
   "metadata": {},
   "source": [
    "## Training Ensemble Models\n",
    "Implements Bagging, Random Forest, and Boosting using Decision Trees.\n",
    "Also combines SVMs in a Voting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b617cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble_models(X_train, y_train,X_test, y_test, svm_models):\n",
    "    print(\"\\nTraining ensemble models...\")\n",
    "\n",
    "    num_models = 20\n",
    "    sample_size = 0.5\n",
    "    feature_sample_size = 0.8\n",
    "    dvc_version = dvc.api.get_url(\"../Data/wdbc.data\", rev=\"HEAD\")  # or use a specific revision\n",
    "    np.random.seed(0)\n",
    "\n",
    "    \n",
    "\n",
    "    # for normal bagging using decision tree\n",
    "    with mlflow.start_run(name = 'Bagging using Decision tree'):\n",
    "        bagging_clf = BaggingClassifier(\n",
    "            base_estimator=DecisionTreeClassifier(),\n",
    "            n_estimators=num_models,\n",
    "            max_features=feature_sample_size,\n",
    "            max_samples=sample_size,\n",
    "            random_state=42\n",
    "        )\n",
    "        bagging_clf.fit(X_train, y_train)\n",
    "        y_pred =  bagging_clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        mlflow.log_param(\"n_estimators\", num_models)\n",
    "        mlflow.log_param(\"max_features\", feature_sample_size)\n",
    "        mlflow.log_param(\"max_samples\", sample_size)\n",
    "        mlflow.log_param(\"accuracy\", accuracy)\n",
    "        mlflow.log_param('dataset_version', dvc_version)\n",
    "        mlflow.sklearn.log_model(bagging_clf, \"BaggingClassifierModel\")\n",
    "\n",
    "\n",
    "    with mlflow.start_run(name = 'RandomForestClassifier'):\n",
    "        rf_clf = RandomForestClassifier(\n",
    "            n_estimators=num_models,\n",
    "            max_features=feature_sample_size,\n",
    "            max_samples=sample_size,\n",
    "            random_state=42\n",
    "        )\n",
    "         \n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        y_pred = rf_clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_param(\"n_estimators\", num_models)\n",
    "        mlflow.log_param(\"max_features\", feature_sample_size)\n",
    "        mlflow.log_param(\"max_samples\", sample_size)\n",
    "        mlflow.log_param(\"accuracy\", accuracy)\n",
    "        mlflow.log_param('dataset_version', dvc_version)\n",
    "        mlflow.sklearn.log_model(rf_clf, \"RandomForestClassifier\")\n",
    "\n",
    "    with mlflow.start_run(name='Boosting using Decision tree'):\n",
    "        boosting_clf = AdaBoostClassifier(\n",
    "            base_estimator=DecisionTreeClassifier(),\n",
    "            n_estimators=num_models,\n",
    "            random_state=42\n",
    "            )\n",
    "        boosting_clf.fit(X_train, y_train)\n",
    "        y_pred = boosting_clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        \n",
    "        mlflow.log_param(\"n_estimators\", num_models)\n",
    "        mlflow.log_param(\"accuracy\", accuracy)\n",
    "        mlflow.log_param('dataset_version', dvc_version)\n",
    "        mlflow.sklearn.log_model(boosting_clf, \"BoostingClassifierModel\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    all_models = {\n",
    "        'SVM (Linear)': svm_models['SVM (Linear)'],\n",
    "        'SVM (RBF)': svm_models['SVM (RBF)'],\n",
    "        'SVM (Polynomial)': svm_models['SVM (Polynomial)'],\n",
    "        'bagging': bagging_clf,\n",
    "        'boosting': boosting_clf,\n",
    "        'Random Forest': rf_clf,\n",
    "    }\n",
    "    \n",
    "\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c470a100",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluates models using classification reports and confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75230fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X_test, y_test):\n",
    "    print(\"\\nEvaluating models...\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nEvaluating {name}:\")\n",
    "\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        \n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(cm)\n",
    "        results[name] = {\n",
    "            'y_pred': y_pred,\n",
    "            'y_prob': y_prob,\n",
    "            'confusion_matrix': cm,\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58898449",
   "metadata": {},
   "source": [
    "## Running the Workflow\n",
    "Now we execute all the steps in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7a308b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "\n",
      "Dataset Overview:\n",
      "Shape: (569, 32)\n",
      "\n",
      "Class distribution:\n",
      "Class\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64\n",
      "Fraud percentage: 37.2583%\n",
      "\n",
      "Checking for missing values:\n",
      "False\n",
      "\n",
      "Basic statistics for anonymized features:\n",
      "                 ID       Class  Radius_Mean  Texture_Mean  Perimeter_Mean  \\\n",
      "count  5.690000e+02  569.000000   569.000000    569.000000      569.000000   \n",
      "mean   3.037183e+07    0.372583    14.127292     19.289649       91.969033   \n",
      "std    1.250206e+08    0.483918     3.524049      4.301036       24.298981   \n",
      "min    8.670000e+03    0.000000     6.981000      9.710000       43.790000   \n",
      "25%    8.692180e+05    0.000000    11.700000     16.170000       75.170000   \n",
      "50%    9.060240e+05    0.000000    13.370000     18.840000       86.240000   \n",
      "75%    8.813129e+06    1.000000    15.780000     21.800000      104.100000   \n",
      "max    9.113205e+08    1.000000    28.110000     39.280000      188.500000   \n",
      "\n",
      "         Area_Mean  Smoothness_Mean  Compactness_Mean  Concavity_Mean  \\\n",
      "count   569.000000       569.000000        569.000000      569.000000   \n",
      "mean    654.889104         0.096360          0.104341        0.088799   \n",
      "std     351.914129         0.014064          0.052813        0.079720   \n",
      "min     143.500000         0.052630          0.019380        0.000000   \n",
      "25%     420.300000         0.086370          0.064920        0.029560   \n",
      "50%     551.100000         0.095870          0.092630        0.061540   \n",
      "75%     782.700000         0.105300          0.130400        0.130700   \n",
      "max    2501.000000         0.163400          0.345400        0.426800   \n",
      "\n",
      "       ConcavePoints_Mean  ...  Radius_Worst  Texture_Worst  Perimeter_Worst  \\\n",
      "count          569.000000  ...    569.000000     569.000000       569.000000   \n",
      "mean             0.048919  ...     16.269190      25.677223       107.261213   \n",
      "std              0.038803  ...      4.833242       6.146258        33.602542   \n",
      "min              0.000000  ...      7.930000      12.020000        50.410000   \n",
      "25%              0.020310  ...     13.010000      21.080000        84.110000   \n",
      "50%              0.033500  ...     14.970000      25.410000        97.660000   \n",
      "75%              0.074000  ...     18.790000      29.720000       125.400000   \n",
      "max              0.201200  ...     36.040000      49.540000       251.200000   \n",
      "\n",
      "        Area_Worst  Smoothness_Worst  Compactness_Worst  Concavity_Worst  \\\n",
      "count   569.000000        569.000000         569.000000       569.000000   \n",
      "mean    880.583128          0.132369           0.254265         0.272188   \n",
      "std     569.356993          0.022832           0.157336         0.208624   \n",
      "min     185.200000          0.071170           0.027290         0.000000   \n",
      "25%     515.300000          0.116600           0.147200         0.114500   \n",
      "50%     686.500000          0.131300           0.211900         0.226700   \n",
      "75%    1084.000000          0.146000           0.339100         0.382900   \n",
      "max    4254.000000          0.222600           1.058000         1.252000   \n",
      "\n",
      "       ConcavePoints_Worst  Symmetry_Worst  FractalDimension_Worst  \n",
      "count           569.000000      569.000000              569.000000  \n",
      "mean              0.114606        0.290076                0.083946  \n",
      "std               0.065732        0.061867                0.018061  \n",
      "min               0.000000        0.156500                0.055040  \n",
      "25%               0.064930        0.250400                0.071460  \n",
      "50%               0.099930        0.282200                0.080040  \n",
      "75%               0.161400        0.317900                0.092080  \n",
      "max               0.291000        0.663800                0.207500  \n",
      "\n",
      "[8 rows x 32 columns]\n",
      "\n",
      "Preprocessing data...\n",
      "Training set shape: (455, 30)\n",
      "Testing set shape: (114, 30)\n",
      "Applying SMOTE to handle class imbalance...\n",
      "After SMOTE - Training set shape: (570, 30)\n",
      "Class distribution after SMOTE: Class\n",
      "1    285\n",
      "0    285\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training SVM models with different kernels...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'dvc' has no attribute 'api'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m load_and_explore_data()\n\u001b[0;32m      2\u001b[0m X_train, X_test, y_train, y_test, scaler, feature_names \u001b[38;5;241m=\u001b[39m preprocess_data(df)\n\u001b[1;32m----> 3\u001b[0m svm_models \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_svm_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m all_models \u001b[38;5;241m=\u001b[39m train_ensemble_models(X_train, y_train,X_test, y_test, svm_models)\n\u001b[0;32m      5\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m evaluate_models(all_models,  X_test, y_test)\n",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m, in \u001b[0;36mtrain_svm_models\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining SVM models with different kernels...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m svm_models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM (Linear)\u001b[39m\u001b[38;5;124m'\u001b[39m: SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM (RBF)\u001b[39m\u001b[38;5;124m'\u001b[39m: SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM (Polynomial)\u001b[39m\u001b[38;5;124m'\u001b[39m: SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m, degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      7\u001b[0m     }\n\u001b[1;32m---> 10\u001b[0m dvc_version \u001b[38;5;241m=\u001b[39m \u001b[43mdvc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241m.\u001b[39mget_url(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/breast_cancer_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, rev\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# or use a specific revision\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m svm_models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name \u001b[38;5;241m=\u001b[39m name):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dvc' has no attribute 'api'"
     ]
    }
   ],
   "source": [
    "df = load_and_explore_data()\n",
    "X_train, X_test, y_train, y_test, scaler, feature_names = preprocess_data(df)\n",
    "svm_models = train_svm_models(X_train, y_train, X_test, y_test)\n",
    "all_models = train_ensemble_models(X_train, y_train,X_test, y_test, svm_models)\n",
    "evaluation_results = evaluate_models(all_models,  X_test, y_test)\n",
    "print(\"\\nExecution completed! Check the output directory for evaluation metrics and explanations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df1ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
